---
title: Streetscape Changes and Infrastructure Equity
subtitle: Orals Prospectus Draft (DO NOT CIRCULATE)
author: Connor P. Jackson
thanks: "Thanks to my advisor, James Sallee, orals chair, Michael Anderson, and outside committee member, Nick Tsivanidis, for invaluable guidance. Thanks to Reed Walker, Timothy McQuade, ARE ERE seminar attendees, and the ARE environment workshop for feedback and suggestions. Thanks to Karen Rosenberg and Kyuhyun (Ryan) Kim for excellent research assistance."
date: now
format:
  pdf: default
  docx:
    toc: true
    toc-depth: 1
linestretch: 1.5
link-citations: true
reference-section-title: References
pdfa: 2a
abstract: |
  Streetscape design is an important determinant of the spatial equilibrium in urban areas. Projects that reallocate street space between users create winners and losers, and understanding the impacts of these projects, who bears the costs and benefits, and how they lead to spatial resorting is an important policy question as cities pursue these projects. This project uses a discontinuity in funding awards from the California Active Transportation Program to provide quasi-random variation in the installation of bike lanes, and the removal of vehicle travel lanes and on-street parking. Using this variation, I will estimate the impacts of these treatments on traffic throughput and speeds, visitation to adjacent businesses, crashes, and fatalities. 
---

```{r}
#| label: setup
#| include: false
library(rdrobust)
# library(rdlocrand)
library(rddensity)
# library(rdmulti)
# library(rdpower)
library(ggplot2)
library(gridExtra)
library(knitr)
library(quarto)
library(english)
library(grateful)
source("atp_data.R")
options(knitr.kable.NA = '')
```

```{r}
#| label: citations
#| echo: false
#| warning: false
citerefs <- cite_packages(output = "citekeys", include.RStudio = TRUE, 
                          cite.tidyverse = TRUE)
nocite_references(citerefs, citation_processor = 'pandoc')
```


# Introduction

In recent years, local governments have been spending substantial amounts of funding on changes to street infrastructure. These projects, which use physical changes to the streetscape to reallocate space between uses and modify user behavior, are often justified as improving safety, health, comfort, efficiency, mode share, and emissions. However, streetscape changes like these are often met with fierce opposition, citing impacts to vehicle throughput, increased travel times, decreased parking availability, and reduced access for business deliveries and customers. In addition, street infrastructure is an important determinant of the spatial equilibrium in urban areas. The allocation of road space for various purposes provides amenities to nearby residents, workers, and visitors, enables the provision of other amenities, like outdoor dining or urban art, and impacts travel times. These amenities and disamenities drive changes to the spatial equilibrium of housing markets and the broader urban landscape.

Even when these changes enhance overall social welfare, they are rarely Pareto improvements. For many residents, particularly low income and primarily renter communities, these changes are often viewed as a harbinger of gentrification and displacement after decades of neglect by municipal public works projects. Given the long history of transportation projects in the United States being used to displace Black and brown neighborhoods, low income areas, and other areas deemed to be "blighted," it is important to understand not just the overall costs and benefits of these infrastructure projects, but also their incidence and distribution as they induce spatial equilibrium changes. 

While some existing observational and engineering research has explored the traffic outcomes of these infrastructure changes [@volker2021], little causally identified economic research exists to explore the broader social impacts, perform welfare analyses, or identify incidence. Existing economic research has focused primarily on the impacts of larger transportation and infrastructure projects such as highway projects and subway expansion [@sleiman2021; @gertler2019; @barwick2021; @gendron-carrier2022; @allen2019; @gonzalez-navarro2016; @tsivanidis2019]. This is the first paper (to my knowledge) that estimates causal impacts of streetscape changes like bike lanes, improved pedestrian infrastructure, and other, smaller-scale projects, and connects them to spatial equilibrium changes.

This research should also be of interest to city planners and transportation departments, who are evaluating changes to their street infrastructure. These projects engender strong feelings both for and against, and both proponents and opponents of a given project point to specific outcomes of a given project as a way to support or oppose its construction. A clear causal identification of the effects of these projects would provide key evidence in these discussions, and help planners and users understand how or whether the positive or negative impacts manifest. In this context, a precisely estimated null effect can be just as valuable to policymakers as a finding of significant impact, as it can demonstrate that a desired goal or a feared impact would not likely come to pass.

To speak to the impacts of these projects, I will pursue several specific research questions. First, what are the impacts of changes to streetscape infrastructure on traffic throughput and speeds, visitors to nearby businesses, and crashes and fatalities? In addition, what are the magnitude and extent of spillovers from these projects, particularly the impacts on traffic, crashes, and business visitation? These first questions together will characterize the set of costs and benefits driven by the projects. 

Next, I will explore the heterogeneity in these effects. Do they differ depending on particular project attributes? Do they accrue differently to local residents than to those coming from farther afield? Do they disproportionately impact those who are just passing through the project area, compared to those who live, work, or visit nearby? How do these differing effects map onto demographic differences, particularly race and household income?

Finally, I will estimate the effects of these projects on spatial equilibrium outcomes. Do the benefits accrue differentially to homeowners and land owners, or do tenants reap benefits as well? How are these changes priced into land values and rents, and thus drive changes in the socioeconomic and racial composition of the surrounding neighborhoods? 

This project uses a regression discontinuity design for identification. Many of these projects receive funding from regional, state, or federal grants, such as California's Active Transportation Program (ATP). This program, and others like it, evaluates submitted projects using a fixed rubric, and assigns each program a numerical score. These funding programs are unable to fund every submitted project, and so define a cutoff score based on the funding available. Projects above the threshold receive funding, while those below the threshold do not receive funding. The funding threshold is not known by the applicants or the evaluators prior to the submission and ranking of the applications, eliminating the possibility of bunching on the running variable.

Receiving funding from any one particular grant program does not guarantee that the project will get built, and cities can proceed with the project using other funds, even if they are denied. Thus, this project will use a fuzzy RD design, with the funding threshold instrumenting for project construction. In addition, application materials and my sources of outcome data include substantial data on baseline conditions for each of the projects, so I will be able to check for pretrends. 

## Literature Review

This project will contribute to several literatures. This project is the first of which I am aware to econometrically estimate the causal impact streetscape improvements, particularly bike lanes. There is an existing literature on the economic impacts of transportation infrastructure. However, these papers generally consider the impacts of large-scale transportation infrastructure, like highways [@sleiman2021] and public transit [@tsivanidis2019; @gendron-carrier2022]. @gonzalez-navarro2016 explore the impacts on paving previously unpaved roads on home values. Impacts of bicycle and pedestrian infrastructure have not been well studied in the economics literature. Meanwhile, there have been a variety of published studies in peer-reviewed and gray literature providing observational or engineering estimates of the impacts of bike lanes and other active transportation infrastructure. @volker2021 provide a review of this literature on bike infrastructure's impact on nearby businesses. These studies, primarily observational studies looking at a single project before and after construction, or with an identified control street, tend to find either positive effects on business outcomes or no clear effect. This study is the first to examine a large panel of proposed bicycle and active transportation infrastructure projects, and causally identify their impacts on relevant outcomes.

Next, it will add to a rich literature on spatial sorting and urban geography, particularly how local amenities impact home values and neighborhood demographics. Much of this literature is rooted in structural models of location choice [@allen2014; @ahlfeldt2015; @allen2019]. @han2021 explores the amenity value of urban trees, using an emerald ash borer infestation in Toronto for exogenous variation in the urban tree canopy. They find that an additional tree increases property values by 0.5–0.9%, and estimate that the urban cooling effect of a tree canopy, while significant, is only a small proportion of the total amenity value of urban trees. @harari2020 describe the value of compact city layouts using topographic barriers to instrument for city shape, while @couture2016 ascribes the value of urban density primarily to having a variety of consumption opportunities nearby. This paper will add to the existing literature by directly valuing the amenities provided by pedestrian- and bicycle-friendly streetscapes, and quantifying the impacts of these amenities on equilibrium sorting. 

# Streetscape Projects Background

## Streetscape Projects Description

In this project, I focus specifically on streets, as distinct from roads or highways. Streets are not just spaces or infrastructure used for transportation and moved through, but are also an important part of a destination itself. The layout and configuration of a street have material impacts on the experience and amenities of a place beyond simply the speed and ease with which travelers can move through it. Streets are complex places, with many attributes that all come together to influence the impact they have on users and occupants. From the number of travel lanes and the lane widths to the state of the sidewalks, to wheelchair cuts and accessibility features, street lighting, trees, benches, and bus stops, all these features come together to impact the experience of the street. For many years, the streets in the United States were designed primarily with single occupancy vehicles in mind. They were designed to move vehicles quickly through the space, and provide fast and easy access to parking. These design choices resulted in degraded experiences for those walking biking or taking public transit through the area. In recent years, cities have been rethinking how they design and allocate Street space and the street scape based on how they impact its users. These projects are designed with a variety of goals in mind, including improving the experience for local residents and business workers the move through the area on foot, reducing greenhouse gas emissions driven by private vehicle use, and improving health, safety, and mode share outcomes. These redesigns of street space come in many forms in or as varied as there are streets to be modified. They often change many attributes at once, but often involve several common features. These projects almost always involve re-allocating space that was previously dedicated to the movement of private vehicles (Such as travel lanes and on street parking) toward other users, by widening sidewalks and defining space dedicated to public transit and bicycles.

Most transportation infrastructure funding in the US is dedicated to private vehicle traffic, primarily allocated by state governments (receiving block grants from the federal Department of Transportation). In contrast, funding for local streetscape improvements are left primarily to the locality (city or county), and is often cobbled together from multiple sources. These projects can be funded through a locality's general street maintenance and paving budget, by a developer providing funding for infrastructure improvements near their projects, or through competitive grant programs. In California in particular, city budgets are often insufficient to fully fund street maintenance and infrastructure improvements as a result of property tax restrictions imposed by Proposition 13 and successor measures. As a result, external funding sources are almost always brought to bear to fund these projects. 

## California Active Transportation Program

The California Active Transportation Program (ATP) is a state funding program jointly administered by the CA Transportation Commission (CTC) and the Department of Transportation (Caltrans). Given the limited funds available to localities for streetscape changes (or even basic road maintenance), the ATP is the primary funding source for many of these types of projects built in the state. The ATP was originally created in 2013 (SB 99), with the goal of increasing active modes of transportation, like walking and biking. The program allocates both state and federal transportation dollars to support these projects, initially funded at approximately $123 million per year, and increased to $223 million annually in 2017, using increased revenues from the state gas tax. Funds have been awarded in five rounds as of 2021, with the sixth round open for applications in 2022. Each funding round includes a statewide component, a component for each of California's eighteen Metropolitan Planning Organizations (MPO), and a component for "small urban and rural" areas that do not fall into an MPO, with statutorily defined budget allocations for each component. 

For each funding round, cities and counties submit detailed application packets describing the projects they wish to fund. These application packets include descriptions of the location of the project, the current street conditions, intended changes and attributes of the project, estimated budget and timeline, and whom the project is likely to benefit. Once applications have been submitted, independent evaluators assign scores to each project using a fixed, pre-announced rubric, in categories like whether the project is in a disadvantaged community, the potential to increase the number of users, the potential to reduce collisions, the level of public participation in the planning process, whether the project design is context-sensitive and transformative to the streetscape, and cost effectiveness. Some of the scored items are objective criteria, such as whether the project is located within a disadvantaged community, and the median household income in the project area. Other questions, however, involve the subjective application of a grading rubric to the applicant's response to a question by project evaluators. While the rubrics are published in advance and applicants can structure their applications to maximize their points on this rubric, the score still relies on the subjective assessment of project evaluators, preventing applicants from having precise control over their scores.

The evaluators—volunteers with expertise in active transportation, safe routes to school projects, disadvantaged communities, and equity—are assigned to teams of two, each evaluating a project individually before reaching a consensus on scores for each question. CTC staff also evaluates and scores applications, and CTC, Caltrans, and volunteer evaluators then meet to discuss and review scores. Evaluators are not assigned applications from their county of residence or occupation, are assigned no more than one application from any given jurisdiction, and sign a conflict of interest form. Once individual item scores are evaluated and vetted, they are totaled, yielding an overall score for each project that can range from -5 to 100, usually in integer or half-integer steps. Projects are then ranked according to their score. [@californiatransportationcommission2022]

Because city budgets are often insufficient to fully fund these projects, the ATP receives far more applications from California localities than its budget can support. ATP thus selects programs for funding in a two-step process. First, once applications have been submitted and scored, ATP staff define a threshold score that corresponds to the exhaustion of the budget for the statewide component of the round. While the CTC provides an estimated amount of funding available in given round when it is opened or applications, the number of applications and the amount of funding requested is not known by applicants, evaluators, or stakeholders until after scores have been finalized. Once scores are finalized, the available budget is used to define the threshold score. This score is not known by anyone until after scores are finalized, including by CTC staff or evaluators. Therefore, while applicants are incentivized to structure their application in order to maximize their score overall, they do not have the information required to precisely manipulate their score specifically around the threshold. Projects which receive a score above the budget threshold score receive the full requested allocation[^partialfunding].

[^partialfunding]: In rare cases, a project is awarded partial funding, but only for the marginal project, and only when the applicants confirm that the project can still be sufficiently completed with the reduced award.

Once the statewide component projects have been identified, the remaining submitted projects are considered for a second level of funding, split by geographic region. The ten largest MPOs[^MPO] each allocate a fixed amount of funding among the projects within their region, while the counties not covered by these ten MPOs are pooled into a single funding allocation round of "small urban and rural areas." The small urban and rural funding component uses the same scores assigned for the statewide funding component, and simply defines an additional, lower score threshold based on the available funding in this funding component. Each MPO can choose to use the statewide criteria and scores to award their component funds, as in the small urban and rural component. In rounds 3--5,  KCOG, StanCOG, and TMPO all elected to have their funding components use the statewide evaluation criteria and scores. Alternatively, MPOs can propose an alternative set of criteria, and, with the approval of ATP staff, evaluate applications using that alternative rubric[^newcall]. However, the criteria are required to be objective, and result in a score or ranking as in the statewide evaluation. Taken together, this funding structure is well matched for a regression discontinuity design with multiple cutoffs/assignment variables [@cattaneo2016; @papay2011]. Conversations with ATP staff indicate that many more projects are worthy of funding than actually receive funding, and that they believe there is little difference in the quality of projects above the threshold than those slightly below the threshold [@newman-burckhard2022]. 

<!-- discuss the MPO criteria more, and whether they are valid -->

[^MPO]: Fresno Council of Governments (FCOG), Kern Council of Governments (KCOG), Metropolitan Transportation Commission (MTC), Sacramento Area Council of Governments (SACOG), San Diego Association of Governments (SANDAG), San Joaquin Council of Governments (SJCOG), Southern California Association of Governments (SCAG), Stanislaus Council of Governments (StanCOG), Tahoe Metropolitan Planning Organization (TMPO), and Tulare County Association of Governments (TCAG). Each MPO corresponds to a single county, with the exception of the MTC, SACOG, SCAG, and TMPO, which cover multiple county regions. 

[^newcall]: MPOs are also empowered to hold an additional call for applications from projects that did not respond to the statewide call. However, I will be excluding these projects from my analysis, because they do not receive statewide scores. 

<!-- Discuss potential for SUTVA violations? -->

# Data Overview

## ATP Projects Data

I have data on the universe of streetscape projects which applied for ATP funding. In addition to the information included in the application packets—the location of the project, the current street conditions, intended changes and attributes of the project, and the estimated budget and timeline—the data include the score assigned to each project, and the current construction status of projects approved for funding, including the date of completion, if completed. The project component data is particularly rich, with detailed variables on many project attributes, such as the length of Class I, II, III, and IV bike lanes installed, length of vehicle travel lanes removed, number of intersections receiving traffic signal upgrades or retiming, number of street lights installed, number of new bike racks installed, and length of sidewalk installed, rebuilt, or widened.

Thus far, I have data on projects submitted to ATP rounds 3, 4, and 5. Round 6 is currently accepting applications, and rounds 1 and 2 data are scanned PDFs, and will thus require manual digitization. @tbl-atp-sample includes summary statistics for the number of projects submitted in each round, as well as the types of attributes commonly included in these projects. The most common project attributes are adding bike lanes, improving or adding sidewalks, and improving pedestrian crossings, including accessibility improvements. While only about 28% of projects explicitly improve intersections and crossings for bicycles, many pedestrian crossing improvements also improve the safety and experience for cyclists. Finally, less than a quarter of projects include any explicit traffic calming measures, such as roundabouts and speed feedback signs, many pedestrian and cycling improvements, such as shortened crossing distances, can still have traffic calming effects. However, only about 10% of projects achieved traffic calming through the removal of vehicle travel lanes.
  
```{r}
#| label: tbl-atp-sample
#| tbl-cap: Summary of Project Attributes by Application Cycle
#| echo: false
atp_summary <- atp[,.(`Projects Submitted` = .N,
                      `Projects Funded` = sum(funded),
                      `Average Project Cost ($1000)` = mean(cost),
                      `Average Award Requested ($1000)` = mean(award_req),
                      `Any Bike Improvements` = mean(any_bike_improv),
                      `Adds Bike Lanes` = mean(bike_lanes > 0), 
                      `Improves Intersections/Crossing for Bikes` = mean(bike_intersect),
                      `Expands Bikeshare` = mean(bikeshare), 
                      `Adds Bike Parking` = mean(bike_parking),
                      `Any Pedestrian Improvements` = mean(any_ped_improv),
                      `Improves or Adds Sidewalks` = mean(sidewalk > 0),
                      `Improves Intersections/Crossings for Pedestrians` = mean(ped_intersect),
                      `Adds Curbcuts or Accessibility Improvements` = mean(ped_curbcut),
                      `Bike and Pedestrian Improvements` = mean(any_bike_improv * any_ped_improv),
                      `Any Vehicle Traffic Calming Improvements` = mean(any_veh_calming),
                      `Removed General Travel Lane` = mean(V.Remove.Travel.Ln > 0)), 
                   keyby = .(Project.Cycle)]
atp_summary <- as.data.frame(t(atp_summary))
colnames(atp_summary) <- paste("Cycle", atp_summary["Project.Cycle", ])
round(atp_summary[row.names(atp_summary) != "Project.Cycle", ], 3)
```

@tbl-bike-lanes explores more deeply the projects that include bike lanes. The average project that includes bike lanes builds approximately 2 lane-miles (i.e. one mile of road with bike lanes in both directions). The most common style is class 2 bicycle lanes—bike lanes on the roadway demarcated by painted lane lines. Class 4 cycletracks, also known as protected bike lanes, are less common, but are increasing in use over time. These bike lanes place some form of physical barrier, such as concrete curbs or bollards, planters, or parked cars, between bicycles and automobile traffic. Class 3 bicycle routes are designated roadways for cycle travel, the infrastructure on which is generally limited to signage and pavement markings indicating the presence of bicycle traffic (commonly referred to as "sharrows"). Class 1 trails are separated bicycle paths for cyclist travel, not incorporated into the street or roadway. 

```{r}
#| label: tbl-bike-lanes
#| tbl-cap: Summary of Projects that Construct Bike Lanes
#| echo: false
bikelanes_sum <- atp[bike_lanes > 0, .(`Projects Submitted` = .N,
                                       `Total Length (lane-feet)` = round(mean(B.Class.1 + B.Class.2 + 
                                                                                 B.Class.3 + B.Class.4), 0),
                                       `Adds Class 1 Trail` = round(mean(B.Class.1 > 0), 3),
                                       `Adds Class 2 Lanes` = round(mean(B.Class.2 > 0), 3),
                                       `Adds Class 3 Route (Sharrows)` = round(mean(B.Class.3 > 0), 3),
                                       `Adds Class 4 Cycletrack` = round(mean(B.Class.4 > 0), 3)),
                     keyby = .(Project.Cycle)]
bikelanes_sum <- as.data.frame(t(bikelanes_sum))
colnames(bikelanes_sum) <- paste("Cycle", bikelanes_sum["Project.Cycle", ])
bikelanes_sum[row.names(bikelanes_sum) != "Project.Cycle", ]
```

While the application data include information about project locations, that information is provided as PDF maps, verbal descriptions, county, city, and a single latitude/longitude point. In order to match the projects to the outcome data, I need to be able to more precisely match outcome data based on the physical extent of the street or project of interest. To do so, I have enlisted the help of two undergraduate research assistants to manually create shapefiles of the projects. The RAs use the information in the application files, including annotated maps and verbal descriptions of the physical extent of the projects, to create a shapefile in ArcGIS of the right of way in which each project is being built. Thus far, the RAs have digitized a first batch 52 projects, and in doing so have figured out the most efficient procedure, so that they are prepared to promptly digitize the remainder once the data are in hand. These shapefiles can then be spatially merged with the outcome data, which are either individual point locations or shapefile polygons themselves.

Using the ATP projects as the sample does imply some potential sample selection issues, some of which influence the interpretation of the estimated effects, while others may threaten the integrity of the research design. Because this is a sample of projects which localities have actively pursued, the treatment effect might differ from an average treatment effect for a bike lane installed on a randomly chosen street. The localities and streets observed in this dataset might quantitatively differ from a random sample of California streets. Localities which are applying for these funds might already be in the process of gentrifying prior to the construction of the streetscape infrastructure changes, or have other differences from localities which did not apply. While these selection concerns impact the external validity of the results, and how one should interpret the estimated coefficients, it should not lead to bias in the estimates, since identification is from project funding at the score threshold, not whether they submitted an application. 

On the other hand, some localities might be better staffed and more capable of assembling successful funding applications, or might be better able to predict where the funding threshold will be. For example, if a particular locality is submitting a large number of applicants, they would have information about a larger fraction of the overall pool of applications. Similarly, a consultant hired by multiple cities to prepare their applications might have insights into a significant fraction of the applications being submitted. In theory, localities could use this information to manipulate their probability of receiving funding around the threshold score. However, since the threshold is not known in advance by anyone, and evaluators are barred from scoring applications from their home county—and consultants may not serve as evaluators at all—it is unlikely that applicants are able to exercise a sufficient degree of control around the threshold to endanger the research design. While applicants are incentivized to manipulate their applications to increase their scores, the RD research design is only violated if they are able to precisely manipulate their probability of treatment around the threshold. I will explore whether this assumption can be rejected in section @sec-identification, where I test for bunching on the running variable to detect score manipulation. 

There are two other data concerns that need to be handled. First is the possibility of repeat applications. In my data, I observe five ATP funding rounds. The rounds are operated independently, with a new budget allocation. However, since many projects fail to receive funding in a given round, localities can, and sometimes do, resubmit applications for projects that were previously denied funding. These resubmissions may be unchanged, or localities may modify their proposed project or application materials in order to achieve a higher score. Because these funding rounds are operated independently, and have their own discontinuity thresholds, repeated submissions across rounds should not violate the RD research design. However, since repeatedly submitted projects are not independent, the standard errors may need to be adjusted to correct for that inter-round correlation. 

The other data concern is imperfect treatment compliance. If a project is denied funding, the applicant locality could decide to allocate other funds to the project, and construct it anyway. Conversely, a project awarded funding could face public opposition and fail to be constructed. As described by @angrist1996, this imperfect compliance alters the interpretation of the estimated coefficients, which are now local average treatment effects (LATE), or the average treatment effect on compliers. To estimate these effects, the research design will use a fuzzy RD to instrument for treatment status. This nuance is important, as the always-takers could be crowding out other amenities by reallocating funding to the project, which could distort the treatment effect. 

<!-- Figure out how two-step funding process works (do most MPOs let CTC administer?), whether that impacts RD design

KCOG and StanCOG both use statewide scores, but sometimes they get too little funding to fund their highest ranked project. How to handle them? Just lump them in with the fuzziness?

MPOs with few applications/awards: TMPO, StanCOG, TCAG, SJCOG. KCOG is borderline. Maybe drop the first four, and let KCOG just be in the statewide pool and pretend there isn't an MPO pool? Since it's so unpredictable? -->

## Outcome Data

To estimate the outcomes of these infrastructure projects, I will use several different data sources. The first is data on visitation to business and other points of interest from [SafeGraph](https://safegraph.com/), a data company that aggregates anonymized location data from numerous applications in order to provide insights about physical places, via the SafeGraph Community. To enhance privacy, SafeGraph excludes census block group information if fewer than five devices visited an establishment in a month from a given census block group. SafeGraph define points of interest (POI), which are specific physical locations that a person might find interesting. POIs can be any physical place humans can visit except single-family homes. SafeGraph categorizes these POIs using the North American Industry Classification System (NAICS) developed by the US Census Bureau to identify different types and purposes of places. The SafeGraph data provide weekly and monthly counts of visitors to points of interest which I can match to the locations of proposed streetscape projects. The counts are based on a sample of mobile phone users, and thus are normalized and weighted to reflect the population as a whole [@safegraph2022]. 

For traffic outcomes, there are several sources of data I am considering. I want to use data on traffic speeds and throughput on specified road segments, and ideally data on cyclist and pedestrian traffic as well. Two well known sources of these data are [American Digital Cartography Inc. (ADCI)](https://www.adci.com) and [Streetlight Data](https://www.streetlightdata.com). ADCI is a provider of [TomTom traffic data](https://www.adci.com/tomtom), and can be purchased for a few thousand dollars. Streetlight have their own data products derived from anonymized location data, similar to SafeGraph. Streetlight offer an academic license which provides free access to their data for up to 500 spatial analysis units. The academic license requires the provision of a "perpetual, irrevocable, sublicensable, and transferable license" to my research and any resultant publications. In addition, because I am analyzing more than 500 projects, I will need to purchase additional spatial analysis units, and Streetlight's data beyond their free academic allocation is much more expensive than ADCI's; likely costing over $100,000. As a result, I am still weighing how to proceed with traffic data sources.

For traffic crash and fatality data, I will use the Transportation Injury Mapping System (TIMS) [@TIMS2022], which sources its data from California's [Statewide Integrated Traffic Records System (SWITRS)](https://www.chp.ca.gov/programs-services/services-information/switrs-internet-statewide-integrated-traffic-records-system). SWITRS records all crashes reported to the California Highway Patrol, including those reported by local agencies and city police departments. It contains geocoded data mapping all reported crashes in California, including the location, time, involved vehicles, severity, and the number of people injured or killed.

In addition, I will ultimately be exploring outcomes on housing, land values, and spatial sorting equilibria. I have yet to identify a specific dataset or datasets to use for these outcomes, but hope to be able to observe land values and real estate prices, commercial rental rates, and residential moves or displacement.

<!-- When will post-treatment observations be? How long does it take travelers to re-equilibrate their commutes following a disruption? Change modes?  -->

## Power Analysis

I will perform some initial calculations with the outcome data I have on hand, in order to get a sense of the available power of my estimators. To perform this analysis, I will need to select the relevant spatial subset of the outcome data that matches with the projects being considered. This data construction will give me at least an approximation of the sample I will have available to me. In order to do this preliminary analysis before I have generated the precise polygons of the project location, I will use the GPS coordinates of each project and simply match locations within a fixed radius of a project. That set of outcome data will be used for preliminary power analysis.

Once I have constructed a dataset of project locations and associated outcome variables, I will specify some placebo "post-treatment" time periods (without the construction having actually occurred) and estimate the treatment effect of this placebo. The standard error on this placebo estimate will give me some sense of the effect size I would be able to detect given my sample. I can perform this analysis for each of the relevant outcome variables being considered.

# Identification and Empirical Strategy {#sec-identification}

Estimating unbiased causal impacts of streetscape infrastructure changes is challenging because these expensive infrastructure projects are rarely assigned in a plausibly random manner to streets. Cities are highly selective about which streets received which changes based on both observable and unobservable (to the researcher) features. To overcome these selection effects, I implement a regression discontinuity (RD) design using features of the Active Transportation Program funding process. This design---initially introduced by @thistlethwaite1960 and more fully and recently described by @lee2010, @imbens2008, @cattaneo2017a, and @cattaneo2022---allows the researcher to learn about causal effects of the treatment on an outcome of interest from the discontinuous change in the probability of receiving treatment at the cutoff. In this section, I will discuss the research design and accompanying empirical strategy more fully, and describe several tests that will be used to verify the validity of this approach in my setting. 

The ATP awards funding to streetscape projects with scores above a threshold defined by the funding allocated by the California legislature. Applicants can manipulate their application packets in order to yield higher scores based on the publicly announced rubric. However, many questions are qualitative, and leave room for the discretion of the application evaluators. This discretion implies that applicants do not have precise control over their scores. In particular, they do not have precise control over their scores around the threshold, since the threshold is not known until after projects have been submitted and scored. In addition, scores range from -5 to 100, with any integer score possible in that range, and half-integer scores appearing occasionally. Over `r atp[, .N]` applications, there are `r atp[, uniqueN(score)]` unique score values within that range. While the distribution of scores is not strictly continuous, this high density of potential values seems reasonable to approximate as a continuous density of scores from -5 to 100, using the continuity approach. However I plan to also explore using the local randomization approach to account for these score mass points in some cases, as described in @cattaneo2018. Taken together, this imprecise control over an approximately continuous running variable (the score) implies that the treatment is as good as randomly assigned around the cutoff [@lee2010]. This local random assignment implies that we can identify a treatment effect using the discontinuity gap at the cutoff.

The two-step funding procedure implemented for the ATP---the first threshold for the statewide funding component, followed by separate thresholds for the regional/MPO components---means I cannot apply the single-threshold RD approach to this analysis. However, the econometrics literature has developed a robust exploration of RD extensions, including an extension to situations with multiple decision variables and/or multiple cutoffs [@cattaneo2016; @papay2011; @reardon2012; @wong2013]. This approach is well suited to the ATP funding structure, as each regional funding component must have a set of objective criteria that leads to a score or ranking for projects, even though they are different scores. In order to validate this approach, I will need to explore the potential for manipulation around the cutoff point for each of the running variables and each of the cutoffs, using the methods discussed below.

Because the treatment probability does not sharply jump from 0 to 1 at the threshold—funded projects could fail to be constructed, and denied projects could be constructed using other funds—this research design will use a "fuzzy" RD approach. As a result, the treatment effect identified will be a weighted local average treatment effect (LATE). The LATE estimates the average treatment effect for compliers [in the language of @angrist1996]: those who construct the project if funded, and those who do not construct the project if not funded. The weights for this weighted LATE are the ex-ante likelihood that an applicant's score is close to the threshold (conditional on observables). The LATE estimation requires two additional assumptions: monotonicity (no defiers who would construct the project if denied funding, but would not construct if awarded funding) and excludability (crossing the score threshold can only impact the outcome via the treatment). While these assumptions cannot be proven to hold, I can provide evidence to support them, and the broader validity of the research design.

## Validation and Manipulation Testing

The main threat to identification in an RD design is systematic differences between treated units just above the cutoff, and untreated units just below the cutoff. This threat can arise for several reasons, such as additional changes taking place at the threshold beyond simply treatment status, and precise manipulation of the running variable by analyzed units in order to select into the treated group  from the untreated group (or vice versa). I will pursue several tests to provide evidence that the treated and control units are ex-ante comparable around the cutoff. First, I inspect the density of the running variable to look for manipulation around the threshold, using both graphical analysis with local polynomial density estimators, and an analytical manipulation test. In both of these sets of tests, I use an asymptotic mean-squared error (ASME) minimizing bandwidth proposed by @calonico2020.

@fig-density-histograms shows local polynomial estimates of the score density on either side of the (normalized) cutoff for statewide funding in the three funding cycles for which I have data, as well as the full, pooled set of projects. A histogram of project scores also appears in the figures. The density estimator uses a quadratic local polynomial, with a cubic polynomial bias-corrected density estimator to construct confidence intervals and a triangular kernel. The bandwidths are chosen separately on each side of the cutoff. In these figures, I do not see any significant evidence of a density discontinuity at the statewide funding cutoff; while the cycle five point estimate visibly differs on either side of the cutoff, the confidence intervals overlap substantially. 

```{r}
#| label: fig-density-histograms
#| fig-cap: Running variable (score) density histograms with estimated quadratic polynomial fits on either side of the threshold. Pictured separately for each funding cycle, as well as pooled. The scores are normalized to the cutoff at 0. 
#| echo: false
#| fig-height: 5
# quadratic polynomial approximated density estimator
# cubic polynomial approximated bias-corrected density estimator (for CIs)
# triangular kernel
# bandwidth (h) chosen by rdbwdensity(), separately left and right of the cutoff
density_tests <- function(scores_norm, title) {
  density_est <- rddensity(scores_norm, c=0, bwselect="each", binoWStep=0.5)
  density_plot <- rdplotdensity(density_est, scores_norm, type="both", 
                                histFillShade=0.4, plotGrid="qs", printPlot=FALSE,
                                xlabel="Normalized Score",
                                ylabel="Density",
                                title=title)
  return(list(density_obj=density_est, density_plot=density_plot, round=title))
}

get_plot <- function(obj) {
  return(obj$density_plot$Estplot)
}

round_density <- lapply(atp[, sort(unique(Project.Cycle))], 
                        function(i) density_tests(atp[(!is.na(score_norm) & 
                                                         Project.Cycle == i), score_norm], 
                                                  paste("Cycle", i)))
pooled_density <- density_tests(atp[!is.na(score_norm), score_norm], "Pooled")

grid.arrange(get_plot(pooled_density), get_plot(round_density[[1]]),
             get_plot(round_density[[2]]), get_plot(round_density[[3]]), ncol=2)
```

@tbl-McCrary-tests provides test statistics for a discontinuity in the density at the running variable for each funding cycle and the pooled projects, as in @fig-density-histograms. This test was first proposed by @mccrary2008, but current forms use a robust bias-correction approach developed in @calonico2014. These tests fail to reject the null hypothesis of continuous density across the statewide funding threshold for all three funding cycles, as well as the pooled results. 

```{r}
#| label: tbl-McCrary-tests
#| echo: false
#| tbl-cap: Test statistics and associated p-values of manipulation tests [originally proposed by @mccrary2008], for each cycle separately and for the pooled projects. 
#| tbl-cap-location: bottom
extract_mccrary <- function(obj) {
  test <- obj$density_obj$test
  return(c(round=obj$round, tstat=round(test$t_jk, 4), pval=round(test$p_jk, 4)))
}

mccrary_res <- data.table(rbind(extract_mccrary(pooled_density), 
                 t(sapply(round_density, extract_mccrary))))
setnames(mccrary_res, c("Funding Cycle", "Test Statistic (Chi-Squared)", "p-value"))
mccrary_res
```

```{r}
#| label: binomial-tests
#| include: false
bino_tests <- function(dens_obj) {
  bino_dt <- as.data.table(data.frame(dens_obj$density_obj$bino))
  return(bino_dt[, .(round=dens_obj$round, window_halfwidth=LeftWindow, LeftN, RightN, pval)])
}

binomial_test_windows <- rbind(bino_tests(pooled_density), 
                               rbindlist(lapply(round_density, bino_tests)))
balance_windows <- binomial_test_windows[pval > 0.05, .(window=max(window_halfwidth)), 
                                         by=.(round)]
```

@tbl-balance-tables provide some information about the balance of project attributes pooled across all `r atp[, english(uniqueN(Project.Cycle))]` project cycles, including average values and two-sample t-statistics. @tbl-balance-tables-1 describes the balance of project attributes for all projects above and below the statewide funding threshold. @tbl-balance-tables-2 also looks above and below the statewide funding cutoff, but only within a window of `r balance_windows[round == "Pooled", window]` points on either side of the threshold score. This window was chosen using a set of nested binomial tests for density balance on either side of the threshold score. Finally, @tbl-balance-tables-3 compares all unfunded projects to all funded projects, regardless of their score. 

```{r}
#| label: tbl-balance-tables
#| echo: false
#| tbl-cap: Balance tables of project attributes 
#| tbl-subcap: 
#|   - All projects, above and below the statewide funding cutoff.
#|   - Projects within a normalized score of ±2.75 of the statewide funding cutoff.
#|   - All projects, selected for funding or not selected for funding (in any funding component)
balance_cols <- c("cost", "award_req", "any_bike_improv", "bike_lanes", 
                  "bike_intersect", "any_ped_improv", "sidewalk", "ped_intersect", 
                  "ped_curbcut", "any_veh_calming")
balance_col_names <- c("Project Cost ($1000)", "ATP Award Requested ($1000)", "Any Bike Improvements",
                       "Lane-Feet of Bike Lane Added", "Improves Intersections/Crossing for Bikes",
                       "Any Pedestrian Improvements", "Improves or Adds Sidewalks", 
                       "Improves Intersections/Crossings for Pedestrians", 
                       "Adds Curbcuts or Accessibility Improvements",
                       "Any Vehicle Traffic Calming Improvements")

balance_table <- function(data, cols, col_names, treatment_var, 
                          group_names=c("Below Cutoff", "Above Cutoff")) {
  bal_means_full <- data[, lapply(.SD, mean), keyby=treatment_var, .SDcols=cols]
  treatment_var_vector <- data[, ..treatment_var][[1]]
  full_bal_t_tests <- data[, lapply(.SD, function(X) t.test(X ~ treatment_var_vector)$statistic), 
                           .SDcols=balance_cols]
  full_bal <- data.frame(merge(as.data.frame(t(bal_means_full)), as.data.frame(t(full_bal_t_tests)), 
                               by="row.names", all=TRUE),
                         row.names = "Row.names")
  colnames(full_bal) <- c(group_names, "t-statistic")
  full_bal <- full_bal[row.names(full_bal) != "funded_statewide", ][cols, ]
  
  countrow <- data.frame(t(data[, .N, keyby=treatment_var]), `t-statistic`=NA)["N", ]
  colnames(countrow) <- c(group_names, "t-statistic")
  rownames(full_bal) <- col_names
  return(rbind(round(full_bal, 3), countrow))
}

balance_table(atp, balance_cols, balance_col_names, "funded_statewide")
balance_table(atp[abs(score_norm) <= 2.75], balance_cols, balance_col_names, "funded_statewide")
balance_table(atp, balance_cols, balance_col_names, "funded", c("Unfunded", "Funded"))
```

Once I have complete data on project construction status, I will recreate @tbl-balance-tables such that the samples considered are based on actual treatment, rather than just the funding thresholds. In addition, as I get additional data on projects, as well as spatially merge baseline outcome and demographic data, I will expand this comparison of covariates, and also generate additional plots of covariates over the running variable across the funding threshold, to detect discontinuities in the covariates, again a sign of manipulation or selection into treatment. For the research design to be valid, covariates should vary continuously across the treatment threshold. I intend to pair these graphs with a joint test of the impact of the threshold on the covariates, using a Seemingly Unrelated Regression (SUR) and $\chi^2$ test [@lee2010 section 4.4.2], and may also pursue placebo tests, in accordance with @imbens2008.

Finally, we consider treatment probability in both the first and second stage. @fig-treatment-prob shows the probability of receiving funding against the normalized running variable across the statewide funding threshold, separately for each funding cycle, as well as all projects pooled together. These plots consider the first stage of my fuzzy RD research design. Because projects receive funding in both the statewide component and the regional component, projects below the statewide funding threshold still receive funding. Unsurprisingly, however, there is still a sizeable jump in funding probability at the statewide threshold, where it jumps to 100%[^unfunded]. In this research design, receiving funding is the instrument, or intention to treat. Once I incorporate the funding scores and thresholds in the regional component, I can present a fuller description of the first stage.

[^unfunded]: There is one project in the data whose score was above the statewide funding threshold, but was not recorded as receiving funding. I suspect this discrepancy represents a data issue rather than a project that truly was denied funding, and am working with ATP Staff to confirm the status of this project. 

```{r}
#| label: fig-treatment-prob
#| fig-cap: Funding probability by normalized score, with cubic polynomial fit.
#| fig-height: 5
#| echo: false
#| warning: false
treatment_prob_plot <- function(scores_norm, treated, title) {
  treatment_plot <- rdplot(treated, scores_norm, p=3, binselect="qspr", hide=TRUE,
                           x.label="Statewide Score (normalized)", 
                           y.label="Funding Probability",
                           title=title)
  return(treatment_plot$rdplot)
}

round_treatment_prob <- lapply(atp[, sort(unique(Project.Cycle))], 
                               function(i) atp[Project.Cycle == i, 
                                               treatment_prob_plot(score_norm, funded, 
                                                                   paste("Cycle", i))])

grid.arrange(atp[, treatment_prob_plot(score_norm, funded, "Pooled")], round_treatment_prob[[1]],
             round_treatment_prob[[2]], round_treatment_prob[[3]], ncol=2)
```

With complete data on project construction status, I will be able to create graphs of _treatment_ probability along the running variable, where the treatment is the construction of an actual project. Because this research design is a fuzzy RD, there will still be some nonzero probability of treatment below the threshold, and units above the threshold may have treatment probability below 1. These graphs will show the magnitude in the jump in treatment probability across the thresholds.

## Empirical Specification and Inference

There are two primary theoretical underpinnings for RD designs: local polynomial approaches which leverage large sample approximations of conditional expectations and rest on continuity assumptions, and finite sample approaches resting on local randomization assumptions, first formalized by @cattaneo2015. @cattaneo2022 provide a review of these two frameworks, their assumptions, and their implications, while @cattaneo2017 applies the more recent local randomization framework to the setting of @ludwig2007, an influential and well known application of the continuity framework. I intend to apply both of these frameworks and compare their estimates. Not only does such an approach test the robustness of my results, but each brings its own strengths and shortcomings. The continuity approach is the more established, well known framework, and also connects most naturally with graphical analysis; an important part of any RD research design. However, the continuity assumptions required do not respond as well to massing on the running variable, and rely on large sample approximations, which may be subject to bias when considering only the relatively small neighborhood around the discontinuity where the inference is most valid. Local randomization, on the other hand, is much better equipped to handle discrete or massed running variables, and uses finite sample inference techniques, which is appealing for my sample of only a few thousand projects, with fewer near the cutoffs. 

For my econometric approach, the RD econometrics literature have settled on a set of data-driven best practices for robust estimation and inference. For the continuity framework analysis, I will estimate local linear and local quadratic nonparametric polynomials, per @gelman2019. My primary specification will use a triangular kernel and mean squared error (MSE)-optimal bandwidth---balancing smoothing bias from misspecification and increased variance from a lower number of observations used---with robust, bias-corrected confidence intervals [@calonico2014; @calonico2018; @calonico2019; @calonico2020], likely clustered at some geographic level. Clustering will be important in this setting, as localities may submit multiple applications. In addition, the standard errors may need to be corrected for the fact that some projects are re-submitted in multiple rounds. For robustness, I will explore the impacts of different kernel functions and bandwidth choices, including coverage error (CER)-optimal bandwidths and separate bandwidths on either side of the cutoffs, compared to a single bandwidth for each cutoff.

For local randomization inference, there are two main choices that need to be made. The first is the conceptual approach for inference (Fisherian fixed potential outcomes, or Neyman random variable potential outcomes), where the Fisherian approach admits the use of finite sample inference methods, while Neyman relies on large sample approximations of the test statistics [@cattaneo2017]. The other is the selection of the analysis window. @cattaneo2015 propose a data-driven method where covariates and placebo outcomes are used, by selecting the largest window in which statistically significant differences in the placebo outcomes or covariates cannot be detected across the treatment threshold. While I plan to use a Fisherian finite sample inference approach, I will test the robustness of my estimates to the choice of inference approach, as well as window size.

While covariates and baseline outcomes prior to treatment are not needed in the regression specification for identification under the continuity framework, they are required for the optimal window selection in the local randomization framework. In addition, I hope to include them in order to soak up additional variation and yield smaller standard errors on the treatment effect, as well as explore heterogeneity in the treatment effect. @calonico2019 lay out a theoretically justified approach for including covariates in an RD specification, and provide adjusted optimal bandwidth choices. In particular, I have access to rich pretrends data, and can potentially leverage the panel structure of my data. There are various approaches in the literature to the inclusion of pretrends data, such as simply including lagged outcome variables as covariates, or implementing a "differences-in-discontinuities" approach [@grembi2016]. This approach was initially used to disambiguate the effect of two treatments that turned on at the treatment threshold. However, it can also be used to increase the precision of estimators beyond that achieved just by including lagged outcome variables as covariates [@beach2017]. This approach may be more challenging to apply in a fuzzy RD setting, as described by @galindosilva2018. I will need to spend more time exploring whether this approach is appropriate for my setting.

In recent years, there has been additional econometric research to develop improved RD estimators and better understand the performance of existing estimators under various scenarios and assumptions, such as @imbens2019 and @bertanha2020. I plan to review these approaches and consider how they might be best integrated into my estimation procedures.

It is possible that my sample will be underpowered to convincingly estimate treatment effects, given my sample size and the structure of the funding program. In that case, I can pursue an alternative empirical strategy, and use a difference-in-difference approach to estimate the treatment effect, given my rich pretrends data. I may also estimate this approach as a robustness check to my primary RD specification, as it leverages different assumptions than the RD specification. 
	
# Conclusion and Next Steps

This project aims to estimate the effects of streetscape infrastructure changes on traffic and business outcomes, as well as explore their implications on the spatial equilibrium through land values and displacement. As I receive data on these infrastructure projects and are able to spatially match them to my outcome data, my next steps will be to perform some initial power analyses as described above. These preliminary analyses will allow me to understand whether I am sufficiently powered with the set of projects currently in place, as well as whether I can expect to be sufficiently powered once more projects are built.

As long as the ATP projects provide a sufficient sample for detecting effects with reasonable precision, I will then turn to more precisely defining the set of geospatially linked outcome data, particularly for the SafeGraph POI data. In addition, I will explore the most appropriate structure for my econometric specification, given its fuzzy RD nature, the inclusion of covariates, and the panel structure of the data. 

The ultimate framing of this paper, and its place in the literature, will depend in part on the success of my RD specification and the effects I am able to estimate. A precisely estimated null result is unlikely to necessitate or benefit from the incorporation of a structural model, but will be a useful result for policymakers considering these projects. On the other hand, statistically significant effects in this reduced form analysis, particularly effects on land values and business outcomes, would be suggestive of future work that employs a structural model of location choice to rationalize the effects. In addition to these reduced form results, I hope to find a framing or structural model that this natural experiment can further explore and parameterize. 
